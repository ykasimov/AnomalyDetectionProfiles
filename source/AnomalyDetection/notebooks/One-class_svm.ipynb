{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yury.kasimov/miniconda3/envs/main/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from Common_functions import global_features, generate_normal_features,generate_anomaly_features, \\\n",
    "                            get_evaluation_matrix, compute_precision_recall_accuracy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, ParameterGrid\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prev_results(idx):\n",
    "    return {1 : 'OCSVM_models/FirstDataset/{}_model.pkl',\n",
    "            2 : 'OCSVM_models/SecondDataset/{}_model.pkl'\n",
    "           }[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal dataset: 1 --- Correspoding anomalous part is 1\n",
    "#                 2 --- Corresponding anomalous parts are 2 and 3\n",
    "normal_dataset = 1\n",
    "\n",
    "# anomalous dataset: 1 --- Emotet malware;  2 --- DarkVNC; 3 --- Simba\n",
    "anomaly_dataset = 1\n",
    "\n",
    "# Set to True to run training.\n",
    "should_train = False\n",
    "\n",
    "\n",
    "global_features = [\n",
    "    'clientDestinationPortTotalBytesUDPEstablished',\n",
    "'clientDestinationPortNumberOfFlowsTCPEstablished',\n",
    "'clientDestinationPortNumberOfFlowsUDPNotEstablished',\n",
    "'clientDestinationPortTotalPacketsTCPEstablished',\n",
    "'clientDestinationPortNumberOfFlowsUDPEstablished',\n",
    "'clientDestinationPortTotalPacketsTCPNotEstablished',\n",
    "'clientDestinationPortTotalBytesUDPNotEstablished',\n",
    "'clientDestinationPortTotalBytesTCPEstablished',\n",
    "'clientDestinationPortTotalPacketsUDPNotEstablished',\n",
    "'clientDestinationPortNumberOfFlowsTCPNotEstablished',\n",
    "'clientDestinationPortTotalBytesTCPNotEstablished',\n",
    "'clientDestinationPortTotalPacketsUDPEstablished']\n",
    "\n",
    "feature_abbrv = {k:''.join([c for c in k if c.isupper()]) for k in global_features }\n",
    "scalers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yury.kasimov/miniconda3/envs/main/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneClassSVM from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# read models.\n",
    "models = {}\n",
    "if not should_train:\n",
    "    models_folder = read_prev_results(normal_dataset)\n",
    "    for feature in global_features:       \n",
    "        with open(models_folder.format(feature), 'rb') as handle:\n",
    "            models[feature] = pickle.load(handle)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(feature_name, normal_dataset, anomaly_dataset):\n",
    "    features = generate_normal_features(feature_name, dataset=normal_dataset)    \n",
    "    transformed_anomaly = generate_anomaly_features(feature_name,dataset=anomaly_dataset)\n",
    "\n",
    "    X_train, X_test, labels_train, labels_test = train_test_split(features, [1]*len(features), test_size=0.2, random_state=42)\n",
    "    X_train, X_val, labels_train, labels_val = train_test_split(features, [1]*len(features), test_size=0.25, random_state=42)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    idx= np.random.choice(range(0,transformed_anomaly.shape[0]),int(transformed_anomaly.shape[0]/2), replace=False)\n",
    "    validation_anomalies = transformed_anomaly[idx,:]\n",
    "    idx = [x for x in range(transformed_anomaly.shape[0]) if x in set(idx)]\n",
    "    test_anomaly = transformed_anomaly[idx,:]\n",
    "\n",
    "    X_val = np.append(X_val, validation_anomalies, axis=0)\n",
    "    X_test = np.append(X_test, test_anomaly, axis=0)\n",
    "    \n",
    "    labels_val = np.append(np.array(labels_val), np.array([-1]*int(transformed_anomaly.shape[0]/2)))\n",
    "    labels_test = np.append(np.array(labels_test), np.array([-1]*int(transformed_anomaly.shape[0]/2)))\n",
    "    benign_val = range(0, labels_val.shape[0]-int(transformed_anomaly.shape[0]/2))\n",
    "    anomaly_val = range(labels_val.shape[0]-int(transformed_anomaly.shape[0]/2), labels_val.shape[0])\n",
    "    benign_test = range(0, labels_test.shape[0]-int(transformed_anomaly.shape[0]/2))\n",
    "    anomaly_test = range(labels_test.shape[0]-int(transformed_anomaly.shape[0]/2), labels_test.shape[0])\n",
    "    \n",
    "    \n",
    "    return (X_train, labels_train), (X_val, labels_val), (X_test, labels_test), (benign_val, anomaly_val), (benign_test, anomaly_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to find the best models for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_train:\n",
    "    scores = {}\n",
    "\n",
    "    should_scale = True\n",
    "    rs = np.random.RandomState(42)\n",
    "    parameters = {'gamma' : np.logspace(-9, 3, 13), 'nu' : np.linspace(0.01, 0.99, 99)}\n",
    "\n",
    "    feature_abbrv = {k:''.join([c for c in k if c.isupper()]) for k in global_features }\n",
    "    dataframe_columns = list(feature_abbrv.values())\n",
    "    experiment_results = pd.DataFrame(columns=['parameters','evaluation']+dataframe_columns)\n",
    "    experiment_results.set_index(['parameters','evaluation'], inplace=True)\n",
    "\n",
    "    test_anomalies = {}\n",
    "    test_labels = {}\n",
    "    for z in ParameterGrid(parameters):\n",
    "        kernel_string = ', '.join('{} : {}'.format(key, val) for key, val in z.items())\n",
    "        print(z)\n",
    "        for feature_name in global_features:       \n",
    "\n",
    "            features = generate_normal_features(feature_name, dataset=normal_dataset)    \n",
    "            transformed_anomaly = generate_anomaly_features(feature_name,dataset=anomaly_dataset)\n",
    "            labels_anomaly = np.array([-1]*transformed_anomaly.shape[0])\n",
    "            X_train, X_test, labels_train, labels_test = train_test_split(features, [1]*len(features), test_size=0.2, random_state=42)\n",
    "            X_train, X_val, labels_train, labels_val = train_test_split(features, [1]*len(features), test_size=0.25, random_state=42)\n",
    "\n",
    "            if should_scale:\n",
    "                scaler = scalers.get(feature_name, StandardScaler(with_std=True, with_mean=True).fit(X_train))\n",
    "                scalers[feature_name] = scaler\n",
    "                X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "            np.random.seed(42)\n",
    "            idx= np.random.choice(range(0,transformed_anomaly.shape[0]),int(transformed_anomaly.shape[0]/2), replace=False)\n",
    "            validation_anomalies = transformed_anomaly[idx,:]\n",
    "            idx = [x for x in range(transformed_anomaly.shape[0]) if x in set(idx)]\n",
    "            test_anomaly = transformed_anomaly[idx,:]\n",
    "            test_anomalies[feature_name] = test_anomaly\n",
    "\n",
    "            X_val = np.append(X_val, validation_anomalies, axis=0)\n",
    "            if should_scale:\n",
    "                X_val = scaler.transform(X_val)\n",
    "            labels_val = np.append(np.array(labels_val), np.array([-1]*int(transformed_anomaly.shape[0]/2)))\n",
    "            benign_val = range(0, labels_val.shape[0]-int(transformed_anomaly.shape[0]/2))\n",
    "            anomaly_val = range(labels_val.shape[0]-int(transformed_anomaly.shape[0]/2), labels_val.shape[0])\n",
    "\n",
    "            svm = OneClassSVM()\n",
    "            svm.set_params(**z)\n",
    "            svm.fit(X_train)\n",
    "            predicted = svm.predict(X_val)\n",
    "\n",
    "            true_positive, false_positive, true_negative, false_negative = \\\n",
    "                                                get_evaluation_matrix(labels=labels_val, predicted=predicted, \n",
    "                                                          benign_range=benign_val, anomaly_range=anomaly_val)\n",
    "\n",
    "\n",
    "            precision, recall, accuracy = compute_precision_recall_accuracy(true_positive=true_positive,\n",
    "                                                                            true_negative=true_negative,\n",
    "                                                                            false_positive=false_positive,\n",
    "                                                                            false_negative=false_negative)\n",
    "            experiment_results.loc[(kernel_string,'tp'), feature_abbrv[feature_name]]=true_positive\n",
    "            experiment_results.loc[(kernel_string,'fp'), feature_abbrv[feature_name]]=false_positive\n",
    "            experiment_results.loc[(kernel_string,'tn'), feature_abbrv[feature_name]]=true_negative\n",
    "            experiment_results.loc[(kernel_string,'fn'), feature_abbrv[feature_name]]=false_negative\n",
    "            experiment_results.loc[(kernel_string,'precision'), feature_abbrv[feature_name]]=precision\n",
    "            experiment_results.loc[(kernel_string,'recall'), feature_abbrv[feature_name]]=recall\n",
    "            experiment_results.loc[(kernel_string,'accuracy'), feature_abbrv[feature_name]]=accuracy\n",
    "            experiment_results.loc[(kernel_string,'FPR'), feature_abbrv[feature_name]]=false_positive/(false_positive+true_negative)\n",
    "            experiment_results.loc[(kernel_string,'TPR'), feature_abbrv[feature_name]]=true_positive/(true_positive+false_negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best parameters based on the results from grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if should_train:\n",
    "    model_params = {k : {} for k in global_features}\n",
    "    min_tpr = 0.167 # 0.167*6 = 1.002 it means we will detect an attack during first 30 minutes\n",
    "    for feature, abriv in feature_abbrv.items():\n",
    "        tmp = experiment_results.unstack(1)[abriv]\n",
    "        tpr_max_val_fpr_less_001 = tmp[tmp['FPR'] < 0.01]['TPR'].max()\n",
    "        tpr_max_val_fpr_min = tmp[tmp['FPR'] == tmp['FPR'].min()]['TPR'].max()\n",
    "        print('=====================\\n',feature)\n",
    "        if tpr_max_val_fpr_min> min_tpr:\n",
    "            print(tmp[tmp['FPR'] == tmp['FPR'].min()][['FPR','TPR', 'precision', 'recall']])\n",
    "            params = tmp[tmp['FPR'] == tmp['FPR'].min()]['TPR'].argmax().split(', ')\n",
    "        elif tpr_max_val_fpr_less_001 > tpr_max_val_fpr_min:\n",
    "            print(tmp[tmp['FPR'] < 0.01][['FPR','TPR','precision', 'recall']])\n",
    "            params = tmp[tmp['FPR'] < 0.01]['TPR'].argmax().split(', ')\n",
    "        else:\n",
    "            print(tmp[tmp['FPR'] == tmp['FPR'].min()][['FPR','TPR','precision', 'recall']])\n",
    "            params = tmp[tmp['FPR'] == tmp['FPR'].min()]['TPR'].argmax().split(', ')\n",
    "        for p in params:\n",
    "            p = p.split(' : ')\n",
    "            p_name = p[0]\n",
    "            p_value = float(p[1])\n",
    "            model_params[feature][p_name] = p_value\n",
    "            \n",
    "    for feature in global_features:\n",
    "        print(feature, model_params[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models for each individual feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clientDestinationPortTotalBytesUDPEstablished\n",
      "fpr:  0.0 tpr:  0.3888888888888889 precision:  1.0\n",
      "========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yury.kasimov/PycharmProjects/AnomalyDetectionProfiles/source/AnomalyDetection/Common_functions.py:128: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive/(true_positive + false_positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clientDestinationPortNumberOfFlowsTCPEstablished\n",
      "fpr:  0.0 tpr:  0.0 precision:  nan\n",
      "========================\n",
      "clientDestinationPortNumberOfFlowsUDPNotEstablished\n",
      "fpr:  0.0 tpr:  0.3888888888888889 precision:  1.0\n",
      "========================\n",
      "clientDestinationPortTotalPacketsTCPEstablished\n",
      "fpr:  0.01098901098901099 tpr:  1.0 precision:  0.9473684210526315\n",
      "========================\n",
      "clientDestinationPortNumberOfFlowsUDPEstablished\n",
      "fpr:  0.01098901098901099 tpr:  0.3888888888888889 precision:  0.875\n",
      "========================\n",
      "clientDestinationPortTotalPacketsTCPNotEstablished\n",
      "fpr:  0.0 tpr:  1.0 precision:  1.0\n",
      "========================\n",
      "clientDestinationPortTotalBytesUDPNotEstablished\n",
      "fpr:  0.01098901098901099 tpr:  0.3888888888888889 precision:  0.875\n",
      "========================\n",
      "clientDestinationPortTotalBytesTCPEstablished\n",
      "fpr:  0.01098901098901099 tpr:  1.0 precision:  0.9473684210526315\n",
      "========================\n",
      "clientDestinationPortTotalPacketsUDPNotEstablished\n",
      "fpr:  0.0 tpr:  0.3888888888888889 precision:  1.0\n",
      "========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yury.kasimov/miniconda3/envs/main/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clientDestinationPortNumberOfFlowsTCPNotEstablished\n",
      "fpr:  0.0 tpr:  1.0 precision:  1.0\n",
      "========================\n",
      "clientDestinationPortTotalBytesTCPNotEstablished\n",
      "fpr:  0.0 tpr:  1.0 precision:  1.0\n",
      "========================\n",
      "clientDestinationPortTotalPacketsUDPEstablished\n",
      "fpr:  0.0 tpr:  0.3888888888888889 precision:  1.0\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "should_scale=True\n",
    "predictions = []\n",
    "for feature in global_features:\n",
    "\n",
    "    (X_train, labels_train), \\\n",
    "    (X_val, labels_val), \\\n",
    "    (X_test, labels_test), \\\n",
    "    (benign_val, anomaly_val), \\\n",
    "    (benign_test, anomaly_test) = get_split_data(feature, normal_dataset, anomaly_dataset)\n",
    "    \n",
    "    if should_scale:\n",
    "        if feature in scalers:\n",
    "            sc = scalers[feature]\n",
    "        else: \n",
    "            sc = StandardScaler(with_std=True, with_mean=True).fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_val = sc.transform(X_val)\n",
    "    \n",
    "    svm = models[feature]\n",
    "    predicted = svm.predict(X_test)\n",
    "    predictions.append(predicted)\n",
    "\n",
    "    true_positive, false_positive, true_negative, false_negative = \\\n",
    "                                            get_evaluation_matrix(labels=labels_test, predicted=predicted, \n",
    "                                                      benign_range=benign_test, anomaly_range=anomaly_test)\n",
    "    \n",
    "    precision, recall, accuracy = compute_precision_recall_accuracy(true_positive=true_positive,\n",
    "                                                                        true_negative=true_negative,\n",
    "                                                                        false_positive=false_positive,\n",
    "                                                                        false_negative=false_negative)\n",
    "    fpr = false_positive/(false_positive+true_negative)\n",
    "    tpr = true_positive/(true_positive+false_negative)\n",
    "    \n",
    "    print(feature)\n",
    "    print('fpr: ',fpr,'tpr: ', tpr, 'precision: ',precision)\n",
    "    print('========================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR ensemble: 0.0\n",
      "TPR ensebmle: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "majority_voting = sum(predictions)\n",
    "majority_voting[majority_voting>0] = 1\n",
    "majority_voting[majority_voting<=0] = -1\n",
    "\n",
    "\n",
    "true_positive, false_positive, true_negative, false_negative = \\\n",
    "                                            get_evaluation_matrix(labels=labels_test, predicted=majority_voting, \n",
    "                                                      benign_range=benign_test, anomaly_range=anomaly_test)\n",
    "\n",
    "fpr = false_positive/(false_positive+true_negative)\n",
    "tpr = true_positive/(true_positive+false_negative)\n",
    "print('FPR ensemble: {}\\nTPR ensebmle: {}'.format(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, model in models.items():\n",
    "    with open(models_folder.format(feature).format(feature), 'wb') as f:\n",
    "        pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:main]",
   "language": "python",
   "name": "conda-env-main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
